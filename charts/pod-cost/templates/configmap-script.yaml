---
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ include "pod-cost.fullname" . }}-script
  namespace: {{ .Release.Namespace }}
  labels:
    {{- include "pod-cost.labels" . | nindent 4 }}
data:
  agent.py: |
    import os
    import time
    import requests
    import logging
    from datetime import datetime
    from kubernetes import client, config

    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    # Load Kubernetes config
    config.load_incluster_config()

    # Initialize clients
    v1 = client.CoreV1Api()
    apps_v1 = client.AppsV1Api()
    batch_v1 = client.BatchV1Api()
    networking_v1 = client.NetworkingV1Api()
    metrics_client = client.CustomObjectsApi()

    # Configuration
    API_ENDPOINT = os.getenv("API_ENDPOINT")
    COLLECTION_INTERVAL = int(os.getenv("COLLECTION_INTERVAL", "60"))
    CLUSTER_NAME = os.getenv("CLUSTER_NAME", "unknown-cluster")
    API_KEY = os.getenv("API_KEY")

    def get_node_metrics():
        """Collect node-level metrics including health data"""
        try:
            nodes = v1.list_node()
            node_metrics = metrics_client.list_cluster_custom_object(
                "metrics.k8s.io", "v1beta1", "nodes"
            )

            metrics = []
            for node in nodes.items:
                node_name = node.metadata.name

                # Find corresponding metrics
                node_metric = next(
                    (m for m in node_metrics["items"] if m["metadata"]["name"] == node_name),
                    None
                )

                # Extract node conditions for health monitoring
                conditions = []
                if node.status.conditions:
                    for condition in node.status.conditions:
                        conditions.append({
                            "type": condition.type,
                            "status": condition.status,
                            "reason": condition.reason or "",
                            "message": condition.message or ""
                        })

                if node_metric:
                    metrics.append({
                        "node_name": node_name,
                        "cpu_usage": node_metric["usage"]["cpu"],
                        "memory_usage": node_metric["usage"]["memory"],
                        "capacity_cpu": node.status.capacity.get("cpu", "0"),
                        "capacity_memory": node.status.capacity.get("memory", "0"),
                        "allocatable_cpu": node.status.allocatable.get("cpu", "0"),
                        "allocatable_memory": node.status.allocatable.get("memory", "0"),
                        "conditions": conditions,
                        "unschedulable": node.spec.unschedulable or False,
                    })

            return metrics
        except Exception as e:
            logger.error(f"Error getting node metrics: {e}")
            return []

    def get_container_state(container_status):
        """Extract container state from container status"""
        if container_status.state:
            if container_status.state.running:
                return "running"
            elif container_status.state.waiting:
                reason = container_status.state.waiting.reason or "waiting"
                return reason  # e.g., "CrashLoopBackOff", "ImagePullBackOff"
            elif container_status.state.terminated:
                return "terminated"
        return "unknown"

    def get_pod_status(pod):
        """Determine overall pod status including container states"""
        phase = pod.status.phase or "Unknown"

        # Check container statuses for more specific status
        if pod.status.container_statuses:
            for cs in pod.status.container_statuses:
                if cs.state and cs.state.waiting:
                    reason = cs.state.waiting.reason
                    if reason in ["CrashLoopBackOff", "ImagePullBackOff", "ErrImagePull", "CreateContainerConfigError"]:
                        return reason

        return phase

    def get_pod_metrics():
        """Collect pod-level metrics including health data"""
        try:
            pods = v1.list_pod_for_all_namespaces()
            pod_metrics = metrics_client.list_cluster_custom_object(
                "metrics.k8s.io", "v1beta1", "pods"
            )

            metrics = []
            for pod in pods.items:
                pod_name = pod.metadata.name
                namespace = pod.metadata.namespace

                # Find corresponding metrics
                pod_metric = next(
                    (m for m in pod_metrics["items"]
                     if m["metadata"]["name"] == pod_name and m["metadata"]["namespace"] == namespace),
                    None
                )

                # Calculate total restart count
                total_restarts = 0
                if pod.status.container_statuses:
                    for cs in pod.status.container_statuses:
                        total_restarts += cs.restart_count or 0

                # Extract pod conditions
                conditions = []
                if pod.status.conditions:
                    for condition in pod.status.conditions:
                        conditions.append({
                            "type": condition.type,
                            "status": condition.status,
                            "reason": condition.reason or "",
                            "message": condition.message or ""
                        })

                # Build container metrics with health data
                container_metrics = []
                container_statuses = {cs.name: cs for cs in (pod.status.container_statuses or [])}

                if pod_metric:
                    for container in pod_metric.get("containers", []):
                        container_name = container["name"]
                        cs = container_statuses.get(container_name)

                        container_metrics.append({
                            "name": container_name,
                            "cpu_usage": container["usage"]["cpu"],
                            "memory_usage": container["usage"]["memory"],
                            "state": get_container_state(cs) if cs else "unknown",
                            "restart_count": cs.restart_count if cs else 0,
                            "ready": cs.ready if cs else False
                        })
                else:
                    # No metrics available, but still include container health data
                    for cs in (pod.status.container_statuses or []):
                        container_metrics.append({
                            "name": cs.name,
                            "cpu_usage": "0",
                            "memory_usage": "0",
                            "state": get_container_state(cs),
                            "restart_count": cs.restart_count or 0,
                            "ready": cs.ready or False
                        })

                # Include all pods, not just running ones (for health tracking)
                metrics.append({
                    "pod_name": pod_name,
                    "namespace": namespace,
                    "node_name": pod.spec.node_name or "",
                    "status": get_pod_status(pod),
                    "phase": pod.status.phase or "Unknown",
                    "restart_count": total_restarts,
                    "conditions": conditions,
                    "containers": container_metrics,
                    "labels": pod.metadata.labels or {}
                })

            return metrics
        except Exception as e:
            logger.error(f"Error getting pod metrics: {e}")
            return []

    def get_namespace_list():
        """Collect all namespaces"""
        try:
            namespaces = v1.list_namespace()
            return [{
                "name": ns.metadata.name,
                "status": ns.status.phase,
                "labels": ns.metadata.labels or {},
                "created_at": ns.metadata.creation_timestamp.isoformat() if ns.metadata.creation_timestamp else None
            } for ns in namespaces.items]
        except Exception as e:
            logger.error(f"Error getting namespaces: {e}")
            return []

    def get_deployments():
        """Collect all deployments"""
        try:
            deployments = apps_v1.list_deployment_for_all_namespaces()
            return [{
                "name": d.metadata.name,
                "namespace": d.metadata.namespace,
                "replicas": d.spec.replicas or 0,
                "ready_replicas": d.status.ready_replicas or 0,
                "available_replicas": d.status.available_replicas or 0,
                "labels": d.metadata.labels or {},
                "selector": d.spec.selector.match_labels if d.spec.selector else {}
            } for d in deployments.items]
        except Exception as e:
            logger.error(f"Error getting deployments: {e}")
            return []

    def get_statefulsets():
        """Collect all statefulsets"""
        try:
            statefulsets = apps_v1.list_stateful_set_for_all_namespaces()
            return [{
                "name": ss.metadata.name,
                "namespace": ss.metadata.namespace,
                "replicas": ss.spec.replicas or 0,
                "ready_replicas": ss.status.ready_replicas or 0,
                "labels": ss.metadata.labels or {},
                "selector": ss.spec.selector.match_labels if ss.spec.selector else {}
            } for ss in statefulsets.items]
        except Exception as e:
            logger.error(f"Error getting statefulsets: {e}")
            return []

    def get_daemonsets():
        """Collect all daemonsets"""
        try:
            daemonsets = apps_v1.list_daemon_set_for_all_namespaces()
            return [{
                "name": ds.metadata.name,
                "namespace": ds.metadata.namespace,
                "desired_number_scheduled": ds.status.desired_number_scheduled or 0,
                "current_number_scheduled": ds.status.current_number_scheduled or 0,
                "number_ready": ds.status.number_ready or 0,
                "labels": ds.metadata.labels or {}
            } for ds in daemonsets.items]
        except Exception as e:
            logger.error(f"Error getting daemonsets: {e}")
            return []

    def get_jobs():
        """Collect all jobs"""
        try:
            jobs = batch_v1.list_job_for_all_namespaces()
            return [{
                "name": j.metadata.name,
                "namespace": j.metadata.namespace,
                "active": j.status.active or 0,
                "succeeded": j.status.succeeded or 0,
                "failed": j.status.failed or 0,
                "completions": j.spec.completions or 1,
                "labels": j.metadata.labels or {}
            } for j in jobs.items]
        except Exception as e:
            logger.error(f"Error getting jobs: {e}")
            return []

    def get_cronjobs():
        """Collect all cronjobs"""
        try:
            cronjobs = batch_v1.list_cron_job_for_all_namespaces()
            return [{
                "name": cj.metadata.name,
                "namespace": cj.metadata.namespace,
                "schedule": cj.spec.schedule,
                "suspend": cj.spec.suspend or False,
                "active_jobs": len(cj.status.active) if cj.status.active else 0,
                "last_schedule_time": cj.status.last_schedule_time.isoformat() if cj.status.last_schedule_time else None,
                "labels": cj.metadata.labels or {}
            } for cj in cronjobs.items]
        except Exception as e:
            logger.error(f"Error getting cronjobs: {e}")
            return []

    def get_services():
        """Collect all services"""
        try:
            services = v1.list_service_for_all_namespaces()
            return [{
                "name": svc.metadata.name,
                "namespace": svc.metadata.namespace,
                "type": svc.spec.type,
                "cluster_ip": svc.spec.cluster_ip,
                "external_ips": svc.spec.external_i_ps or [],
                "ports": [{"port": p.port, "target_port": str(p.target_port), "protocol": p.protocol} for p in (svc.spec.ports or [])],
                "selector": svc.spec.selector or {},
                "labels": svc.metadata.labels or {}
            } for svc in services.items]
        except Exception as e:
            logger.error(f"Error getting services: {e}")
            return []

    def get_configmaps():
        """Collect all configmaps (metadata only, not data for security)"""
        try:
            configmaps = v1.list_config_map_for_all_namespaces()
            return [{
                "name": cm.metadata.name,
                "namespace": cm.metadata.namespace,
                "data_keys": list(cm.data.keys()) if cm.data else [],
                "labels": cm.metadata.labels or {}
            } for cm in configmaps.items]
        except Exception as e:
            logger.error(f"Error getting configmaps: {e}")
            return []

    def get_secrets():
        """Collect all secrets (metadata only, NEVER data for security)"""
        try:
            secrets = v1.list_secret_for_all_namespaces()
            return [{
                "name": s.metadata.name,
                "namespace": s.metadata.namespace,
                "type": s.type,
                "data_keys": list(s.data.keys()) if s.data else [],
                "labels": s.metadata.labels or {}
            } for s in secrets.items]
        except Exception as e:
            logger.error(f"Error getting secrets: {e}")
            return []

    def get_pvcs():
        """Collect all PersistentVolumeClaims"""
        try:
            pvcs = v1.list_persistent_volume_claim_for_all_namespaces()
            return [{
                "name": pvc.metadata.name,
                "namespace": pvc.metadata.namespace,
                "status": pvc.status.phase,
                "storage_class": pvc.spec.storage_class_name,
                "capacity": pvc.status.capacity.get("storage") if pvc.status.capacity else None,
                "access_modes": pvc.spec.access_modes or [],
                "labels": pvc.metadata.labels or {}
            } for pvc in pvcs.items]
        except Exception as e:
            logger.error(f"Error getting pvcs: {e}")
            return []

    def get_ingresses():
        """Collect all ingresses"""
        try:
            ingresses = networking_v1.list_ingress_for_all_namespaces()
            return [{
                "name": ing.metadata.name,
                "namespace": ing.metadata.namespace,
                "class_name": ing.spec.ingress_class_name,
                "hosts": [rule.host for rule in (ing.spec.rules or []) if rule.host],
                "tls": [{"hosts": tls.hosts, "secret_name": tls.secret_name} for tls in (ing.spec.tls or [])],
                "labels": ing.metadata.labels or {}
            } for ing in ingresses.items]
        except Exception as e:
            logger.error(f"Error getting ingresses: {e}")
            return []

    def get_all_resources():
        """Collect all extended resource metrics"""
        return {
            "namespaces": get_namespace_list(),
            "deployments": get_deployments(),
            "statefulsets": get_statefulsets(),
            "daemonsets": get_daemonsets(),
            "jobs": get_jobs(),
            "cronjobs": get_cronjobs(),
            "services": get_services(),
            "configmaps": get_configmaps(),
            "secrets": get_secrets(),
            "pvcs": get_pvcs(),
            "ingresses": get_ingresses()
        }

    def send_metrics_to_api(node_metrics, pod_metrics, resource_metrics):
        """Send collected metrics to the API with authentication"""
        payload = {
            "cluster_name": CLUSTER_NAME,
            "timestamp": datetime.utcnow().isoformat(),
            "node_metrics": node_metrics,
            "pod_metrics": pod_metrics,
            "resource_metrics": resource_metrics
        }

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {API_KEY}"
        }

        try:
            response = requests.post(
                API_ENDPOINT,
                json=payload,
                headers=headers,
                timeout=30
            )
            response.raise_for_status()
            logger.info(f"Successfully sent metrics to API. Status: {response.status_code}")
            return True
        except requests.exceptions.RequestException as e:
            logger.error(f"Error sending metrics to API: {e}")
            if hasattr(e, 'response') and e.response is not None:
                logger.error(f"Response: {e.response.text}")
            return False

    def main():
        logger.info(f"Starting PodCost metrics agent")
        logger.info(f"Cluster: {CLUSTER_NAME}")
        logger.info(f"API Endpoint: {API_ENDPOINT}")
        logger.info(f"Collection interval: {COLLECTION_INTERVAL} seconds")

        if not API_KEY:
            logger.error("API_KEY is not set. Please configure your API key from podcost.io dashboard.")
            return

        logger.info("API key configured - using authenticated mode")

        while True:
            try:
                logger.info("Collecting metrics...")

                node_metrics = get_node_metrics()
                pod_metrics = get_pod_metrics()
                resource_metrics = get_all_resources()

                logger.info(f"Collected metrics for {len(node_metrics)} nodes, {len(pod_metrics)} pods, and {len(resource_metrics.get('deployments', []))} deployments")

                if node_metrics or pod_metrics:
                    send_metrics_to_api(node_metrics, pod_metrics, resource_metrics)
                else:
                    logger.warning("No metrics collected")

            except Exception as e:
                logger.error(f"Error in main loop: {e}")

            time.sleep(COLLECTION_INTERVAL)

    if __name__ == "__main__":
        main()
